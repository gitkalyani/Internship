{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb912b56",
   "metadata": {},
   "source": [
    "### WEB SCRAPING – ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df4f1d0",
   "metadata": {},
   "source": [
    "#### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10\n",
    "jobs data.\n",
    "This task will be done in following steps:\n",
    "\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "\n",
    "3. Then click the searchbutton.\n",
    "\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4a9e6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\asus\\downloads\\new folder (2)\\lib\\site-packages (4.8.3)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\asus\\downloads\\new folder (2)\\lib\\site-packages (from selenium) (0.10.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\asus\\downloads\\new folder (2)\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\asus\\downloads\\new folder (2)\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\asus\\downloads\\new folder (2)\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\asus\\downloads\\new folder (2)\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\asus\\downloads\\new folder (2)\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: idna in c:\\users\\asus\\downloads\\new folder (2)\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\asus\\downloads\\new folder (2)\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\asus\\downloads\\new folder (2)\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\asus\\downloads\\new folder (2)\\lib\\site-packages (from trio~=0.17->selenium) (1.1.1)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\asus\\downloads\\new folder (2)\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\asus\\downloads\\new folder (2)\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\asus\\downloads\\new folder (2)\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\asus\\downloads\\new folder (2)\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\asus\\downloads\\new folder (2)\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\asus\\downloads\\new folder (2)\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9516a86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83a96a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\ASUS\\Downloads\\chromedriver_win32\\Chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d9dbc197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the noukari page on automated chrome browser\n",
    "\n",
    "driver.get(' https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f65b60ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entering the job name\n",
    "\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "66729a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entering the location \n",
    "\n",
    "location = driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4830ffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for search button\n",
    "\n",
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b2f25f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36afd52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping job title from the given page\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH, '//a[@class=\"title ellipsis\"]' )\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "    \n",
    "# Scraping job location from the given page\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH, '//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#  Scraping company name from the given page\n",
    "\n",
    "company_tags = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]' )\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# Scraping job experience from the given page\n",
    "\n",
    "experience_tags = driver.find_elements(By.XPATH, '//span[@class=\"ellipsis fleft expwdth\"]' )\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_required.append(experience)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b782bcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "## Checking the lenght\n",
    "\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b334b67",
   "metadata": {},
   "source": [
    "### Making Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6fdf8c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Comoany_Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Ingersoll Rand</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Procurement Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Schneider Electric</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Clarivate</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst || Bangalore || Male/ Female || 1...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>TeamLease</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst - EdTech</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Talentstack</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Unusual Hire</td>\n",
       "      <td>1-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Engineer/Data Analyst</td>\n",
       "      <td>Hybrid - Bangalore/Bengaluru, Kolkata, Hyderab...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>6-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst - Contractual</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Search Advisers Services Guj</td>\n",
       "      <td>2-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                       Data Analyst   \n",
       "1                                       Data Analyst   \n",
       "2                           Procurement Data Analyst   \n",
       "3                                       Data Analyst   \n",
       "4                                       Data Analyst   \n",
       "5  Data Analyst || Bangalore || Male/ Female || 1...   \n",
       "6                              Data Analyst - EdTech   \n",
       "7                                       Data Analyst   \n",
       "8                         Data Engineer/Data Analyst   \n",
       "9                         Data Analyst - Contractual   \n",
       "\n",
       "                                            Location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2                                Bangalore/Bengaluru   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8  Hybrid - Bangalore/Bengaluru, Kolkata, Hyderab...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                   Comoany_Name Experience  \n",
       "0                Ingersoll Rand    3-6 Yrs  \n",
       "1                           ANZ    5-8 Yrs  \n",
       "2            Schneider Electric    2-3 Yrs  \n",
       "3                           ANZ    5-9 Yrs  \n",
       "4                     Clarivate    2-4 Yrs  \n",
       "5                     TeamLease    1-5 Yrs  \n",
       "6                   Talentstack    2-6 Yrs  \n",
       "7                  Unusual Hire    1-4 Yrs  \n",
       "8                 Tech Mahindra   6-11 Yrs  \n",
       "9  Search Advisers Services Guj    2-3 Yrs  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Title':job_title, 'Location':job_location, 'Comoany_Name':company_name, 'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f736357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7577eff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "96876b44",
   "metadata": {},
   "source": [
    "### Q2:Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. Youhave to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data. This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "    \n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "\n",
    "3. Then click the searchbutton.\n",
    "\n",
    "4. Then scrape the data for the first 10 jobs results youget.\n",
    "\n",
    "5. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d2d900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\ASUS\\Downloads\\chromedriver_win32\\Chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "58e8ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the noukari page on automated chrome browser\n",
    "\n",
    "driver.get(' https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e09bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entering the job name\n",
    "\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bff8d938",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entering the location \n",
    "\n",
    "location = driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60f8f8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for search button\n",
    "\n",
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "24d85fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4db8722",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping job title from the given page\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH, '//a[@class=\"title ellipsis\"]' )\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "    \n",
    "# Scraping job location from the given page\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH, '//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#  Scraping company name from the given page\n",
    "\n",
    "company_tags = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]' )\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# Scraping job experience from the given page\n",
    "\n",
    "experience_tags = driver.find_elements(By.XPATH, '//span[@class=\"ellipsis fleft expwdth\"]' )\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_required.append(experience)\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6179f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "## Checking the lenght\n",
    "\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4b743d",
   "metadata": {},
   "source": [
    "### Making DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57e792d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Comoany_Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Professional - IBM SPSS Statistic...</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Mumbai, Pune, Chennai</td>\n",
       "      <td>Hexaware Technologies</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior data scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>4-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist_NLP</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>5-11 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Persistent</td>\n",
       "      <td>5-12 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Manager - Innovations Hub - Machine Learning</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>PwC</td>\n",
       "      <td>7-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Engineer Consultant Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Engineer Consultant-Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Verizon</td>\n",
       "      <td>4-9 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Data Science Professional - IBM SPSS Statistic...   \n",
       "1                            Data Science Specialist   \n",
       "2                   Analystics & Modeling Specialist   \n",
       "3                              Senior data scientist   \n",
       "4                                 Data Scientist_NLP   \n",
       "5                                     Data Scientist   \n",
       "6                    Machine Learning (AI) Architect   \n",
       "7       Manager - Innovations Hub - Machine Learning   \n",
       "8            Senior Engineer Consultant Data Science   \n",
       "9            Senior Engineer Consultant-Data Science   \n",
       "\n",
       "                                            Location           Comoany_Name  \\\n",
       "0  Bangalore/Bengaluru, Noida, Mumbai, Pune, Chennai  Hexaware Technologies   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...              Accenture   \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...              Accenture   \n",
       "3  Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...      Fractal Analytics   \n",
       "4  Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...      Fractal Analytics   \n",
       "5  Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...      Fractal Analytics   \n",
       "6  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...             Persistent   \n",
       "7  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...                    PwC   \n",
       "8                                Bangalore/Bengaluru                Verizon   \n",
       "9                                Bangalore/Bengaluru                Verizon   \n",
       "\n",
       "  Experience  \n",
       "0    5-8 Yrs  \n",
       "1    2-4 Yrs  \n",
       "2    6-8 Yrs  \n",
       "3    4-8 Yrs  \n",
       "4   5-11 Yrs  \n",
       "5    3-7 Yrs  \n",
       "6   5-12 Yrs  \n",
       "7    7-9 Yrs  \n",
       "8    4-9 Yrs  \n",
       "9    4-9 Yrs  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Title':job_title, 'Location':job_location, 'Comoany_Name':company_name, 'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffc89c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5df00c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03c5852e",
   "metadata": {},
   "source": [
    "### Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3b94a5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\ASUS\\Downloads\\chromedriver_win32\\Chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "671c795b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the noukari page on automated chrome browser\n",
    "\n",
    "driver.get(' https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "8ea35fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entering the job name\n",
    "\n",
    "designation = driver.find_element(By.CLASS_NAME,\"suggestor-input \")\n",
    "\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "63a1353f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for search button\n",
    "\n",
    "search = driver.find_element(By.CLASS_NAME,\"qsbSubmit\")\n",
    "\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "613c149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entering the location after applying filter\n",
    "\n",
    "location = driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[2]/div[2]/div[2]/label/p/span[1]\")\n",
    "\n",
    "location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "48f1f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entering the salary after applying filter\n",
    "\n",
    "salary= driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/div/section[1]/div[2]/div[3]/div[2]/div[2]/label/p/span[1]\")\n",
    "\n",
    "salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "c8b87789",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "2b43d32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping job title from the given page\n",
    "\n",
    "title_tags = driver.find_elements(By.XPATH, '//a[@class=\"title ellipsis\"]' )\n",
    "for i in title_tags[0:10]:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "    \n",
    "# Scraping job location from the given page\n",
    "\n",
    "location_tags = driver.find_elements(By.XPATH, '//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location = i.text\n",
    "    job_location.append(location)\n",
    "    \n",
    "#  Scraping company name from the given page\n",
    "\n",
    "company_tags = driver.find_elements(By.XPATH, '//a[@class=\"subTitle ellipsis fleft\"]' )\n",
    "for i in company_tags[0:10]:\n",
    "    company = i.text\n",
    "    company_name.append(company)\n",
    "    \n",
    "# Scraping job experience from the given page\n",
    "\n",
    "experience_tags = driver.find_elements(By.XPATH, '//span[@class=\"ellipsis fleft expwdth\"]' )\n",
    "for i in experience_tags[0:10]:\n",
    "    experience = i.text\n",
    "    experience_required.append(experience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "f4bdc09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "## Checking the lenght\n",
    "\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28531072",
   "metadata": {},
   "source": [
    "### Making DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "631f32d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Comoany_Name</th>\n",
       "      <th>Experience</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Temp. WFH - Kochi/Cochin, Kolkata, Hyderabad/S...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Tabsquare</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, United States (USA), Bulgaria</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Analyst-Data Science</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>AMERICAN EXPRESS</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Chenani, Gurgaon/Gurug...</td>\n",
       "      <td>RecruitEForU</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Assistant Manager/Senior Manager - Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Huquo Consulting Pvt. Ltd</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                                     Data Scientist   \n",
       "1                              Junior Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3                                     Data Scientist   \n",
       "4                                     Data Scientist   \n",
       "5                              Junior Data Scientist   \n",
       "6                               Analyst-Data Science   \n",
       "7                               Analyst-Data Science   \n",
       "8                              Senior Data Scientist   \n",
       "9  Assistant Manager/Senior Manager - Data Scientist   \n",
       "\n",
       "                                            Location  \\\n",
       "0  Temp. WFH - Kochi/Cochin, Kolkata, Hyderabad/S...   \n",
       "1  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "2              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "3  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "4  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...   \n",
       "5    Gurgaon/Gurugram, United States (USA), Bulgaria   \n",
       "6                                   Gurgaon/Gurugram   \n",
       "7                                   Gurgaon/Gurugram   \n",
       "8  Hyderabad/Secunderabad, Chenani, Gurgaon/Gurug...   \n",
       "9              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "\n",
       "                Comoany_Name Experience  \n",
       "0                  Cognizant   6-10 Yrs  \n",
       "1                   Analytos    0-2 Yrs  \n",
       "2                  Blackbuck    3-7 Yrs  \n",
       "3                  Tabsquare    1-3 Yrs  \n",
       "4                   Analytos    2-4 Yrs  \n",
       "5                     Adidas    1-6 Yrs  \n",
       "6           AMERICAN EXPRESS    0-3 Yrs  \n",
       "7           AMERICAN EXPRESS    0-3 Yrs  \n",
       "8               RecruitEForU    3-8 Yrs  \n",
       "9  Huquo Consulting Pvt. Ltd    2-7 Yrs  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Title':job_title, 'Location':job_location, 'Comoany_Name':company_name, 'Experience':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0832f2ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7881e127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4ca97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5d79408a",
   "metadata": {},
   "source": [
    "### Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "230c35a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\ASUS\\Downloads\\chromedriver_win32\\Chromedriver.exe')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "ebe12462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the flipkart page on automated chrome browser\n",
    "\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b186af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entering the name 'sunglasses'\n",
    "\n",
    "glass = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "\n",
    "glass.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "0ebad2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for search button\n",
    "\n",
    "search = driver.find_element(By.CLASS_NAME,\"_34RNph\")\n",
    "\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "bda14f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_title = []\n",
    "prod_descr = []\n",
    "price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "1dd5d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Brand from the given page\n",
    "\n",
    "brand_tags = driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]' )\n",
    "for i in brand_tags[0:39]:\n",
    "    brand_1 = i.text\n",
    "    brand_title.append(brand_1)\n",
    "    \n",
    "    \n",
    "# Scraping product discription from the given page\n",
    "\n",
    "descr_tags = driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "for i in descr_tags[0:40]:\n",
    "    descr_1 = i.text\n",
    "    prod_descr.append(descr_1)\n",
    "    \n",
    "#  Scraping price from the given page\n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]' )\n",
    "for i in price_tags[0:39]:\n",
    "    price_1 = i.text\n",
    "    price.append(price_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "7a547caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 39 39\n"
     ]
    }
   ],
   "source": [
    "print(len(brand_title),len(prod_descr),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "68e89fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_2 = driver.find_element(By.CLASS_NAME,\"_1LKTO3\")\n",
    "\n",
    "next_2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "050c589e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Brand from the given page\n",
    "\n",
    "brand_tags = driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]' )\n",
    "for i in brand_tags[0:40]:\n",
    "    brand_1 = i.text\n",
    "    brand_title.append(brand_1)\n",
    "    \n",
    "    \n",
    "# Scraping product discription from the given page\n",
    "\n",
    "descr_tags = driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "for i in descr_tags[0:40]:\n",
    "    descr_1 = i.text\n",
    "    prod_descr.append(descr_1)\n",
    "    \n",
    "#  Scraping price from the given page\n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]' )\n",
    "for i in price_tags[0:40]:\n",
    "    price_1 = i.text\n",
    "    price.append(price_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "b8c27a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79 79 79\n"
     ]
    }
   ],
   "source": [
    "print(len(brand_title),len(prod_descr),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "089d66b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_3 = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]\")\n",
    "\n",
    "next_3.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9b3a3e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Brand from the given page\n",
    "\n",
    "brand_tags = driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]' )\n",
    "for i in brand_tags[0:21]:\n",
    "    brand_1 = i.text\n",
    "    brand_title.append(brand_1)\n",
    "    \n",
    "    \n",
    "# Scraping product discription from the given page\n",
    "\n",
    "descr_tags = driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "for i in descr_tags[0:21]:\n",
    "    descr_1 = i.text\n",
    "    prod_descr.append(descr_1)\n",
    "    \n",
    "#  Scraping price from the given page\n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]' )\n",
    "for i in price_tags[0:21]:\n",
    "    price_1 = i.text\n",
    "    price.append(price_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "1c893676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(brand_title),len(prod_descr),len(price))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f81218",
   "metadata": {},
   "source": [
    "### Making DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1e82773c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_Name</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Resist</td>\n",
       "      <td>Polarized Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹1,399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Silver Kartz</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (53)</td>\n",
       "      <td>₹149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Polarized Retro Square Sunglasses (Free Size)</td>\n",
       "      <td>₹544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (55)</td>\n",
       "      <td>₹216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>DEIXELS</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Aviator S...</td>\n",
       "      <td>₹929</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Brand_Name                                Product_Description   Price\n",
       "0          Resist          Polarized Wayfarer Sunglasses (Free Size)  ₹1,399\n",
       "1    Silver Kartz      UV Protection Wayfarer Sunglasses (Free Size)    ₹267\n",
       "2       Elligator  UV Protection Cat-eye, Retro Square, Oval, Rou...    ₹149\n",
       "3            SRPM             UV Protection Wayfarer Sunglasses (50)    ₹149\n",
       "4       Elligator             UV Protection Wayfarer Sunglasses (53)    ₹149\n",
       "..            ...                                                ...     ...\n",
       "95       Fastrack              UV Protection Aviator Sunglasses (58)    ₹922\n",
       "96       Fastrack      Polarized Retro Square Sunglasses (Free Size)    ₹544\n",
       "97         PIRASO              UV Protection Aviator Sunglasses (55)    ₹216\n",
       "98        DEIXELS   UV Protection Rectangular Sunglasses (Free Size)    ₹230\n",
       "99  VINCENT CHASE  by Lenskart Polarized, UV Protection Aviator S...    ₹929\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Brand_Name':brand_title, 'Product_Description':prod_descr, 'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a4071c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af733aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e9a361",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d17041f4",
   "metadata": {},
   "source": [
    "### Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link:\n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/productreviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&marketplace=FLIPKART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "id": "96c8072d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\ASUS\\Downloads\\chromedriver_win32\\Chromedriver.exe')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "id": "1bf158f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the flipkart review page on automated chrome browser\n",
    "\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "id": "c8c39d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_title = []\n",
    "review_summary = []\n",
    "full_review = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "3ee46195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping ratings from the given page\n",
    "\n",
    "rating_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]' )\n",
    "for i in rating_tags[0:9]:\n",
    "    rating_1 = i.text\n",
    "    rating_title.append(rating_1)\n",
    "    \n",
    "    \n",
    "# Scraping rating summary from the given page\n",
    "\n",
    "summary_tags = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summary_tags[0:9]:\n",
    "    summary_1 = i.text\n",
    "    review_summary.append(summary_1)\n",
    "    \n",
    "#  Scraping full review from the given page\n",
    "\n",
    "review_tags = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]' )\n",
    "for i in review_tags[0:9]:\n",
    "    review_1 = i.text\n",
    "    full_review.append(review_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "512c207c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 9 9\n"
     ]
    }
   ],
   "source": [
    "print(len(rating_title),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "id": "9b8d0170",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_2 = driver.find_element(By.CLASS_NAME,\"_1LKTO3\")\n",
    "\n",
    "next_2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "id": "9a5a82c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping ratings from the given page\n",
    "\n",
    "rating_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]' )\n",
    "for i in rating_tags[0:9]:\n",
    "    rating_1 = i.text\n",
    "    rating_title.append(rating_1)\n",
    "    \n",
    "    \n",
    "# Scraping job location from the given page\n",
    "\n",
    "summary_tags = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summary_tags[0:9]:\n",
    "    summary_1 = i.text\n",
    "    review_summary.append(summary_1)\n",
    "    \n",
    "#  Scraping company name from the given page\n",
    "\n",
    "review_tags = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]' )\n",
    "for i in review_tags[0:9]:\n",
    "    review_1 = i.text\n",
    "    full_review.append(review_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "id": "ac7772c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18 18\n"
     ]
    }
   ],
   "source": [
    "print(len(rating_title),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "id": "1679f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_3 = driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\")\n",
    "\n",
    "next_3.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "4477d8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping ratings from the given page\n",
    "\n",
    "rating_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]' )\n",
    "for i in rating_tags[0:9]:\n",
    "    rating_1 = i.text\n",
    "    rating_title.append(rating_1)\n",
    "    \n",
    "    \n",
    "# Scraping job location from the given page\n",
    "\n",
    "summary_tags = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summary_tags[0:9]:\n",
    "    summary_1 = i.text\n",
    "    review_summary.append(summary_1)\n",
    "    \n",
    "#  Scraping company name from the given page\n",
    "\n",
    "review_tags = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]' )\n",
    "for i in review_tags[0:9]:\n",
    "    review_1 = i.text\n",
    "    full_review.append(review_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "cda858a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27 27 27\n"
     ]
    }
   ],
   "source": [
    "print(len(rating_title),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "73c06745",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_4 = driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\")\n",
    "\n",
    "next_4.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "id": "0ad75cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping ratings from the given page\n",
    "\n",
    "rating_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]' )\n",
    "for i in rating_tags[0:9]:\n",
    "    rating_1 = i.text\n",
    "    rating_title.append(rating_1)\n",
    "    \n",
    "    \n",
    "# Scraping job location from the given page\n",
    "\n",
    "summary_tags = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summary_tags[0:9]:\n",
    "    summary_1 = i.text\n",
    "    review_summary.append(summary_1)\n",
    "    \n",
    "#  Scraping company name from the given page\n",
    "\n",
    "review_tags = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]' )\n",
    "for i in review_tags[0:9]:\n",
    "    review_1 = i.text\n",
    "    full_review.append(review_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "id": "37ee6dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36 36 36\n"
     ]
    }
   ],
   "source": [
    "print(len(rating_title),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "c06e9cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_5 = driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\")\n",
    "\n",
    "next_5.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "6330bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping ratings from the given page\n",
    "\n",
    "rating_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]' )\n",
    "for i in rating_tags[0:9]:\n",
    "    rating_1 = i.text\n",
    "    rating_title.append(rating_1)\n",
    "    \n",
    "    \n",
    "# Scraping job location from the given page\n",
    "\n",
    "summary_tags = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summary_tags[0:9]:\n",
    "    summary_1 = i.text\n",
    "    review_summary.append(summary_1)\n",
    "    \n",
    "#  Scraping company name from the given page\n",
    "\n",
    "review_tags = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]' )\n",
    "for i in review_tags[0:9]:\n",
    "    review_1 = i.text\n",
    "    full_review.append(review_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "457178df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 45 45\n"
     ]
    }
   ],
   "source": [
    "print(len(rating_title),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "c77f3c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_6 = driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\")\n",
    "\n",
    "next_6.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "e8a61af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping ratings from the given page\n",
    "\n",
    "rating_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]' )\n",
    "for i in rating_tags[0:9]:\n",
    "    rating_1 = i.text\n",
    "    rating_title.append(rating_1)\n",
    "    \n",
    "    \n",
    "# Scraping job location from the given page\n",
    "\n",
    "summary_tags = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summary_tags[0:9]:\n",
    "    summary_1 = i.text\n",
    "    review_summary.append(summary_1)\n",
    "    \n",
    "#  Scraping company name from the given page\n",
    "\n",
    "review_tags = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]' )\n",
    "for i in review_tags[0:9]:\n",
    "    review_1 = i.text\n",
    "    full_review.append(review_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "6d340033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54 54 54\n"
     ]
    }
   ],
   "source": [
    "print(len(rating_title),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "972e41b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_7 = driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\")\n",
    "\n",
    "next_7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "id": "b0d088a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping ratings from the given page\n",
    "\n",
    "rating_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]' )\n",
    "for i in rating_tags[0:9]:\n",
    "    rating_1 = i.text\n",
    "    rating_title.append(rating_1)\n",
    "    \n",
    "    \n",
    "# Scraping job location from the given page\n",
    "\n",
    "summary_tags = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summary_tags[0:9]:\n",
    "    summary_1 = i.text\n",
    "    review_summary.append(summary_1)\n",
    "    \n",
    "#  Scraping company name from the given page\n",
    "\n",
    "review_tags = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]' )\n",
    "for i in review_tags[0:9]:\n",
    "    review_1 = i.text\n",
    "    full_review.append(review_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "3d582678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 63 63\n"
     ]
    }
   ],
   "source": [
    "print(len(rating_title),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "6ae91417",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_8 = driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\")\n",
    "\n",
    "next_8.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "d8c8c99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping ratings from the given page\n",
    "\n",
    "rating_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]' )\n",
    "for i in rating_tags[0:9]:\n",
    "    rating_1 = i.text\n",
    "    rating_title.append(rating_1)\n",
    "    \n",
    "    \n",
    "# Scraping job location from the given page\n",
    "\n",
    "summary_tags = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summary_tags[0:9]:\n",
    "    summary_1 = i.text\n",
    "    review_summary.append(summary_1)\n",
    "    \n",
    "#  Scraping company name from the given page\n",
    "\n",
    "review_tags = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]' )\n",
    "for i in review_tags[0:9]:\n",
    "    review_1 = i.text\n",
    "    full_review.append(review_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "id": "b44423c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72 72 72\n"
     ]
    }
   ],
   "source": [
    "print(len(rating_title),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "c2293661",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_9 = driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\")\n",
    "\n",
    "next_9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "id": "ba8090e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping ratings from the given page\n",
    "\n",
    "rating_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]' )\n",
    "for i in rating_tags[0:9]:\n",
    "    rating_1 = i.text\n",
    "    rating_title.append(rating_1)\n",
    "    \n",
    "    \n",
    "# Scraping job location from the given page\n",
    "\n",
    "summary_tags = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summary_tags[0:9]:\n",
    "    summary_1 = i.text\n",
    "    review_summary.append(summary_1)\n",
    "    \n",
    "#  Scraping company name from the given page\n",
    "\n",
    "review_tags = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]' )\n",
    "for i in review_tags[0:9]:\n",
    "    review_1 = i.text\n",
    "    full_review.append(review_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "id": "26ff21de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81 81 81\n"
     ]
    }
   ],
   "source": [
    "print(len(rating_title),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "id": "acad0b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_10 = driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\")\n",
    "\n",
    "next_10.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "e224c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping ratings from the given page\n",
    "\n",
    "rating_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]' )\n",
    "for i in rating_tags[0:9]:\n",
    "    rating_1 = i.text\n",
    "    rating_title.append(rating_1)\n",
    "    \n",
    "    \n",
    "# Scraping job location from the given page\n",
    "\n",
    "summary_tags = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summary_tags[0:9]:\n",
    "    summary_1 = i.text\n",
    "    review_summary.append(summary_1)\n",
    "    \n",
    "#  Scraping company name from the given page\n",
    "\n",
    "review_tags = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]' )\n",
    "for i in review_tags[0:9]:\n",
    "    review_1 = i.text\n",
    "    full_review.append(review_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "id": "56efdb09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 90 90\n"
     ]
    }
   ],
   "source": [
    "print(len(rating_title),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "4a0bb7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_11 = driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]\")\n",
    "\n",
    "next_11.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "a46444dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping ratings from the given page\n",
    "\n",
    "rating_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]' )\n",
    "for i in rating_tags[0:9]:\n",
    "    rating_1 = i.text\n",
    "    rating_title.append(rating_1)\n",
    "    \n",
    "    \n",
    "# Scraping job location from the given page\n",
    "\n",
    "summary_tags = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summary_tags[0:9]:\n",
    "    summary_1 = i.text\n",
    "    review_summary.append(summary_1)\n",
    "    \n",
    "#  Scraping company name from the given page\n",
    "\n",
    "review_tags = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]' )\n",
    "for i in review_tags[0:9]:\n",
    "    review_1 = i.text\n",
    "    full_review.append(review_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "b7330e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 94 94\n"
     ]
    }
   ],
   "source": [
    "print(len(rating_title),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "1401f485",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_12 = driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[7]/div/div/nav/a[12]\")\n",
    "\n",
    "next_12.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "id": "d7aed3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping ratings from the given page\n",
    "\n",
    "rating_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]' )\n",
    "for i in rating_tags[0:6]:\n",
    "    rating_1 = i.text\n",
    "    rating_title.append(rating_1)\n",
    "    \n",
    "    \n",
    "# Scraping job location from the given page\n",
    "\n",
    "summary_tags = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summary_tags[0:6]:\n",
    "    summary_1 = i.text\n",
    "    review_summary.append(summary_1)\n",
    "    \n",
    "#  Scraping company name from the given page\n",
    "\n",
    "review_tags = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]' )\n",
    "for i in review_tags[0:6]:\n",
    "    review_1 = i.text\n",
    "    full_review.append(review_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "id": "ae3b235c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98 98 98\n"
     ]
    }
   ],
   "source": [
    "print(len(rating_title),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "id": "691706fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_13 = driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[7]/div/div/nav/a[12]\")\n",
    "\n",
    "next_13.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "8d784892",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_14 = driver.find_element(By.XPATH,\"/html/body/div/div/div[3]/div/div/div[2]/div[5]/div/div/nav/a[12]\")\n",
    "\n",
    "next_14.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "431ff18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping ratings from the given page\n",
    "\n",
    "rating_tags = driver.find_elements(By.XPATH, '//div[@class=\"_3LWZlK _1BLPMq\"]' )\n",
    "for i in rating_tags[0:2]:\n",
    "    rating_1 = i.text\n",
    "    rating_title.append(rating_1)\n",
    "    \n",
    "    \n",
    "# Scraping job location from the given page\n",
    "\n",
    "summary_tags = driver.find_elements(By.XPATH, '//p[@class=\"_2-N8zT\"]')\n",
    "for i in summary_tags[0:2]:\n",
    "    summary_1 = i.text\n",
    "    review_summary.append(summary_1)\n",
    "    \n",
    "#  Scraping company name from the given page\n",
    "\n",
    "review_tags = driver.find_elements(By.XPATH, '//div[@class=\"t-ZTKy\"]' )\n",
    "for i in review_tags[0:2]:\n",
    "    review_1 = i.text\n",
    "    full_review.append(review_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "id": "089a28cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(rating_title),len(review_summary),len(full_review))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d07a1e2",
   "metadata": {},
   "source": [
    "### Making DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "id": "a9be545e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Review</th>\n",
       "      <th>Full_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Value for money iphone😊</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>GOOD PURCHASE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Got mobile @56,990 on 8 oct 2020 when all othe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Buying this 2022. But this doesn't feel old ❤️...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Superb ever phone &amp; value for money 👍once u us...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Ratings               Review  \\\n",
       "0        5       Simply awesome   \n",
       "1        5     Perfect product!   \n",
       "2        5  Best in the market!   \n",
       "3        4      Value-for-money   \n",
       "4        5   Highly recommended   \n",
       "..     ...                  ...   \n",
       "95       5            Just wow!   \n",
       "96       5            Excellent   \n",
       "97       5            Excellent   \n",
       "98       5            Just wow!   \n",
       "99       5    Worth every penny   \n",
       "\n",
       "                                          Full_Review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   I'm Really happy with the product\\nDelivery wa...  \n",
       "4   It's my first time to use iOS phone and I am l...  \n",
       "..                                                ...  \n",
       "95                            Value for money iphone😊  \n",
       "96                                      GOOD PURCHASE  \n",
       "97  Got mobile @56,990 on 8 oct 2020 when all othe...  \n",
       "98  Buying this 2022. But this doesn't feel old ❤️...  \n",
       "99  Superb ever phone & value for money 👍once u us...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 537,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Ratings':rating_title, 'Review':review_summary, 'Full_Review':full_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7ee14f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3756bbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e48d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5fcbb33c",
   "metadata": {},
   "source": [
    "### Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "c6441602",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\ASUS\\Downloads\\chromedriver_win32\\Chromedriver.exe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "32fc2494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the flipkart page on automated chrome browser\n",
    "\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "d74cfe28",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entering the name 'sneakers'\n",
    "\n",
    "sneakre = driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "\n",
    "sneakre.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "id": "997e6500",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for search button\n",
    "\n",
    "search = driver.find_element(By.CLASS_NAME,\"_34RNph\")\n",
    "\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "6147725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_title = []\n",
    "prod_descr = []\n",
    "price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "083038a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Brand from the given page\n",
    "\n",
    "brand_tags = driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]' )\n",
    "for i in brand_tags[0:39]:\n",
    "    brand_1 = i.text\n",
    "    brand_title.append(brand_1)\n",
    "    \n",
    "    \n",
    "# Scraping product discription from the given page\n",
    "\n",
    "descr_tags = driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "for i in descr_tags[0:39]:\n",
    "    descr_1 = i.text\n",
    "    prod_descr.append(descr_1)\n",
    "    \n",
    "#  Scraping price from the given page\n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]' )\n",
    "for i in price_tags[0:39]:\n",
    "    price_1 = i.text\n",
    "    price.append(price_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "id": "646162c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 39 39\n"
     ]
    }
   ],
   "source": [
    "print(len(brand_title),len(prod_descr),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "77f3b486",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_2 = driver.find_element(By.CLASS_NAME,\"_1LKTO3\")\n",
    "\n",
    "next_2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "a05d9419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Brand from the given page\n",
    "\n",
    "brand_tags = driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]' )\n",
    "for i in brand_tags[0:39]:\n",
    "    brand_1 = i.text\n",
    "    brand_title.append(brand_1)\n",
    "    \n",
    "    \n",
    "# Scraping product discription from the given page\n",
    "\n",
    "descr_tags = driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "for i in descr_tags[0:39]:\n",
    "    descr_1 = i.text\n",
    "    prod_descr.append(descr_1)\n",
    "    \n",
    "#  Scraping price from the given page\n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]' )\n",
    "for i in price_tags[0:39]:\n",
    "    price_1 = i.text\n",
    "    price.append(price_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "a6f8d08a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78 78 78\n"
     ]
    }
   ],
   "source": [
    "print(len(brand_title),len(prod_descr),len(price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "88d2f4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_3 = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]\")\n",
    "\n",
    "next_3.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "62b4e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Brand from the given page\n",
    "\n",
    "brand_tags = driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]' )\n",
    "for i in brand_tags[0:22]:\n",
    "    brand_1 = i.text\n",
    "    brand_title.append(brand_1)\n",
    "    \n",
    "    \n",
    "# Scraping product discription from the given page\n",
    "\n",
    "descr_tags = driver.find_elements(By.XPATH, '//a[@class=\"IRpwTa\"]')\n",
    "for i in descr_tags[0:22]:\n",
    "    descr_1 = i.text\n",
    "    prod_descr.append(descr_1)\n",
    "    \n",
    "#  Scraping price from the given page\n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH, '//div[@class=\"_30jeq3\"]' )\n",
    "for i in price_tags[0:22]:\n",
    "    price_1 = i.text\n",
    "    price.append(price_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "id": "9701c15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(brand_title),len(prod_descr),len(price))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b8e733",
   "metadata": {},
   "source": [
    "### Making DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "22d78649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_Name</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SFR</td>\n",
       "      <td>2006 Trenddy Fashion Sporty Casuals Sneakers R...</td>\n",
       "      <td>₹299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMICO</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic| Lightweight| Premiun| Comfort| Summ...</td>\n",
       "      <td>₹399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>FORSETI</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>Stylish Comfortable Casual Sneakers Shoes for ...</td>\n",
       "      <td>₹587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>EZDEZARIO</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ESMEE</td>\n",
       "      <td>500 Sneakers For Men</td>\n",
       "      <td>₹1,799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>New Balance</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹4,113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Brand_Name                                Product_Description   Price\n",
       "0        BRUTON      Combo Pack Of 2 Casual Shoes Sneakers For Men    ₹599\n",
       "1        BRUTON      Combo Pack Of 2 Casual Shoes Sneakers For Men    ₹499\n",
       "2           SFR  2006 Trenddy Fashion Sporty Casuals Sneakers R...    ₹299\n",
       "3         AMICO                                   Sneakers For Men    ₹387\n",
       "4          aadi  Synthetic| Lightweight| Premiun| Comfort| Summ...    ₹399\n",
       "..          ...                                                ...     ...\n",
       "95      FORSETI                                   Sneakers For Men    ₹629\n",
       "96       Shozie  Stylish Comfortable Casual Sneakers Shoes for ...    ₹587\n",
       "97    EZDEZARIO                                   Sneakers For Men    ₹494\n",
       "98        ESMEE                               500 Sneakers For Men  ₹1,799\n",
       "99  New Balance      Combo Pack Of 2 Casual Shoes Sneakers For Men  ₹4,113\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Brand_Name':brand_title, 'Product_Description':prod_descr, 'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dee2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fae2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21654471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6541ef99",
   "metadata": {},
   "source": [
    "### Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then set CPU Type filter to “Intel Core i7” \n",
    "\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "a2b9e380",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\ASUS\\Downloads\\chromedriver_win32\\Chromedriver.exe')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "8cbd738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the Amazone page on automated chrome browser\n",
    "\n",
    "driver.get(' https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "id": "22cbc10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entering the name “Laptop”\n",
    "\n",
    "laptop = driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "\n",
    "laptop.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "id": "d8f3857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for search button\n",
    "\n",
    "search = driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span\")\n",
    "\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "fd9af03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Entering the  “Intel Core i7” after applying filter\n",
    "\n",
    "intel_core_i7= driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[6]/li[12]/span/a/span\")\n",
    "\n",
    "intel_core_i7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "a3ce97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand_title = []\n",
    "ratings = []\n",
    "price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "bf668eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Brand from the given page\n",
    "\n",
    "brand_tags = driver.find_elements(By.XPATH, '//span[@class=\"a-size-medium a-color-base a-text-normal\"]' )\n",
    "for i in brand_tags[0:10]:\n",
    "    brand_1 = i.text\n",
    "    brand_title.append(brand_1)\n",
    "    \n",
    "    \n",
    "# Scraping product discription from the given page\n",
    "\n",
    "rate_tags = driver.find_elements(By.XPATH, '//span[@class=\"a-size-base\"]')\n",
    "for i in rate_tags[0:10]:\n",
    "    rate_1 = i.text\n",
    "    ratings.append(rate_1)\n",
    "    \n",
    "#  Scraping price from the given page\n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH, '//span[@class=\"a-price-whole\"]' )\n",
    "for i in price_tags[0:10]:\n",
    "    price_1 = i.text\n",
    "    price.append(price_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "b0059acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(brand_title),len(ratings),len(price))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa170c8b",
   "metadata": {},
   "source": [
    "### Making DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "120f2747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand_Name</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Samsung Galaxy Book2 (NP750) Intel 12th Gen co...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Victus Gaming Latest 12th Gen Intel Core i7...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>79,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1,00,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Renewed) HP ELITEBOOK 840 G5 (Core i7 8th GEN...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>31,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS Vivobook S15 OLED 2022, 15.6\" 39.62 cms F...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LG Gram16 Intel EVO-[12th Gen Core i7/Win11/16...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>99,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS TUF Gaming F15 (2022), 15.6\" (39.62 cms) ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>94,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>31,592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) HP 840g3 Elitebook 14 Inch Screen La...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>92,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Dash F15, Intel Core i7-12650H 12th G...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>83,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Brand_Name Ratings     Price\n",
       "0  Samsung Galaxy Book2 (NP750) Intel 12th Gen co...     4.1    79,990\n",
       "1  HP Victus Gaming Latest 12th Gen Intel Core i7...     4.3    79,990\n",
       "2  ASUS TUF Gaming F15 (2022), 15.6\"(39.62 cms) F...     4.4  1,00,990\n",
       "3  (Renewed) HP ELITEBOOK 840 G5 (Core i7 8th GEN...     4.0    31,490\n",
       "4  ASUS Vivobook S15 OLED 2022, 15.6\" 39.62 cms F...     4.1    84,990\n",
       "5  LG Gram16 Intel EVO-[12th Gen Core i7/Win11/16...     4.1    99,990\n",
       "6  ASUS TUF Gaming F15 (2022), 15.6\" (39.62 cms) ...     4.3    94,990\n",
       "7  Lenovo IdeaPad Slim 5 Intel Core i7 12th Gen 1...     3.0    31,592\n",
       "8  (Renewed) HP 840g3 Elitebook 14 Inch Screen La...     4.0    92,990\n",
       "9  ASUS TUF Dash F15, Intel Core i7-12650H 12th G...     4.3    83,990"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Brand_Name':brand_title, 'Ratings':ratings, 'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fab8e7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18f1617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b77298",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f5a09c4",
   "metadata": {},
   "source": [
    "### Q8: Write a python program to scrape data for Top 1000 Quotes of All Time. The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "d3370922",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\ASUS\\Downloads\\chromedriver_win32\\Chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "id": "74dc441a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the page on automated chrome browser\n",
    "\n",
    "driver.get('https://www.azquotes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "35b2e1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for TopQuotes button\n",
    "\n",
    "Top_Quotes = driver.find_element(By.XPATH,\"/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a\")\n",
    "\n",
    "Top_Quotes.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "id": "44562d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote_title = []\n",
    "authors = []\n",
    "type_of_quotes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "id": "2f35b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Quotes from the given page\n",
    "\n",
    "quote_tags = driver.find_elements(By.XPATH, '//a[@class=\"title\"]' )\n",
    "for i in quote_tags[0:100]:\n",
    "    quote_1 = i.text\n",
    "    quote_title.append(quote_1)\n",
    "    \n",
    "    \n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags = driver.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags[0:100]:\n",
    "    author_1 = i.text\n",
    "    authors.append(author_1)\n",
    "    \n",
    "#  Scraping type of quotes from the given page\n",
    "\n",
    "type_tags = driver.find_elements(By.XPATH, '//div[@class=\"tags\"]' )\n",
    "for i in type_tags[0:100]:\n",
    "    type_1 = i.text\n",
    "    type_of_quotes.append(type_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "id": "11e933fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(quote_title),len(authors),len(type_of_quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "id": "ea23982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_2 = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[12]/a\")\n",
    "\n",
    "next_2.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "id": "957906c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Quotes from the given page\n",
    "\n",
    "quote_tags = driver.find_elements(By.XPATH, '//a[@class=\"title\"]' )\n",
    "for i in quote_tags[0:100]:\n",
    "    quote_1 = i.text\n",
    "    quote_title.append(quote_1)\n",
    "    \n",
    "    \n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags = driver.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags[0:100]:\n",
    "    author_1 = i.text\n",
    "    authors.append(author_1)\n",
    "    \n",
    "#  Scraping type of quotes from the given page\n",
    "\n",
    "type_tags = driver.find_elements(By.XPATH, '//div[@class=\"tags\"]' )\n",
    "for i in type_tags[0:100]:\n",
    "    type_1 = i.text\n",
    "    type_of_quotes.append(type_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "id": "631b8ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 200 200\n"
     ]
    }
   ],
   "source": [
    "print(len(quote_title),len(authors),len(type_of_quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "503af958",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_3 = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[13]/a\")\n",
    "\n",
    "next_3.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "id": "916cd0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Quotes from the given page\n",
    "\n",
    "quote_tags = driver.find_elements(By.XPATH, '//a[@class=\"title\"]' )\n",
    "for i in quote_tags[0:100]:\n",
    "    quote_1 = i.text\n",
    "    quote_title.append(quote_1)\n",
    "    \n",
    "    \n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags = driver.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags[0:100]:\n",
    "    author_1 = i.text\n",
    "    authors.append(author_1)\n",
    "    \n",
    "#  Scraping type of quotes from the given page\n",
    "\n",
    "type_tags = driver.find_elements(By.XPATH, '//div[@class=\"tags\"]' )\n",
    "for i in type_tags[0:100]:\n",
    "    type_1 = i.text\n",
    "    type_of_quotes.append(type_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "id": "af8d3c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 300 300\n"
     ]
    }
   ],
   "source": [
    "print(len(quote_title),len(authors),len(type_of_quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "id": "3453ffc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_4 = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[13]/a\")\n",
    "\n",
    "next_4.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "id": "3af03997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Quotes from the given page\n",
    "\n",
    "quote_tags = driver.find_elements(By.XPATH, '//a[@class=\"title\"]' )\n",
    "for i in quote_tags[0:100]:\n",
    "    quote_1 = i.text\n",
    "    quote_title.append(quote_1)\n",
    "    \n",
    "    \n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags = driver.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags[0:100]:\n",
    "    author_1 = i.text\n",
    "    authors.append(author_1)\n",
    "    \n",
    "#  Scraping type of quotes from the given page\n",
    "\n",
    "type_tags = driver.find_elements(By.XPATH, '//div[@class=\"tags\"]' )\n",
    "for i in type_tags[0:100]:\n",
    "    type_1 = i.text\n",
    "    type_of_quotes.append(type_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "id": "c82a4212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400 400 400\n"
     ]
    }
   ],
   "source": [
    "print(len(quote_title),len(authors),len(type_of_quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "id": "37b389e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_5 = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[13]/a\")\n",
    "\n",
    "next_5.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "f3f32107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Quotes from the given page\n",
    "\n",
    "quote_tags = driver.find_elements(By.XPATH, '//a[@class=\"title\"]' )\n",
    "for i in quote_tags[0:100]:\n",
    "    quote_1 = i.text\n",
    "    quote_title.append(quote_1)\n",
    "    \n",
    "    \n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags = driver.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags[0:100]:\n",
    "    author_1 = i.text\n",
    "    authors.append(author_1)\n",
    "    \n",
    "#  Scraping type of quotes from the given page\n",
    "\n",
    "type_tags = driver.find_elements(By.XPATH, '//div[@class=\"tags\"]' )\n",
    "for i in type_tags[0:100]:\n",
    "    type_1 = i.text\n",
    "    type_of_quotes.append(type_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "id": "1a89a513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 500 500\n"
     ]
    }
   ],
   "source": [
    "print(len(quote_title),len(authors),len(type_of_quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "id": "22fd3a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_6 = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[13]/a\")\n",
    "\n",
    "next_6.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "id": "f54f0190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Quotes from the given page\n",
    "\n",
    "quote_tags = driver.find_elements(By.XPATH, '//a[@class=\"title\"]' )\n",
    "for i in quote_tags[0:100]:\n",
    "    quote_1 = i.text\n",
    "    quote_title.append(quote_1)\n",
    "    \n",
    "    \n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags = driver.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags[0:100]:\n",
    "    author_1 = i.text\n",
    "    authors.append(author_1)\n",
    "    \n",
    "#  Scraping type of quotes from the given page\n",
    "\n",
    "type_tags = driver.find_elements(By.XPATH, '//div[@class=\"tags\"]' )\n",
    "for i in type_tags[0:100]:\n",
    "    type_1 = i.text\n",
    "    type_of_quotes.append(type_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "id": "e07a2bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 600 600\n"
     ]
    }
   ],
   "source": [
    "print(len(quote_title),len(authors),len(type_of_quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "293b7bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_7 = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[13]/a\")\n",
    "\n",
    "next_7.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "518a8dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Quotes from the given page\n",
    "\n",
    "quote_tags = driver.find_elements(By.XPATH, '//a[@class=\"title\"]' )\n",
    "for i in quote_tags[0:100]:\n",
    "    quote_1 = i.text\n",
    "    quote_title.append(quote_1)\n",
    "    \n",
    "    \n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags = driver.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags[0:100]:\n",
    "    author_1 = i.text\n",
    "    authors.append(author_1)\n",
    "    \n",
    "#  Scraping type of quotes from the given page\n",
    "\n",
    "type_tags = driver.find_elements(By.XPATH, '//div[@class=\"tags\"]' )\n",
    "for i in type_tags[0:100]:\n",
    "    type_1 = i.text\n",
    "    type_of_quotes.append(type_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "id": "ee157b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700 700 700\n"
     ]
    }
   ],
   "source": [
    "print(len(quote_title),len(authors),len(type_of_quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "id": "bd923556",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_8 = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[13]/a\")\n",
    "\n",
    "next_8.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "id": "e209436e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Quotes from the given page\n",
    "\n",
    "quote_tags = driver.find_elements(By.XPATH, '//a[@class=\"title\"]' )\n",
    "for i in quote_tags[0:100]:\n",
    "    quote_1 = i.text\n",
    "    quote_title.append(quote_1)\n",
    "    \n",
    "    \n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags = driver.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags[0:100]:\n",
    "    author_1 = i.text\n",
    "    authors.append(author_1)\n",
    "    \n",
    "#  Scraping type of quotes from the given page\n",
    "\n",
    "type_tags = driver.find_elements(By.XPATH, '//div[@class=\"tags\"]' )\n",
    "for i in type_tags[0:100]:\n",
    "    type_1 = i.text\n",
    "    type_of_quotes.append(type_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "id": "ec74e7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800 800 800\n"
     ]
    }
   ],
   "source": [
    "print(len(quote_title),len(authors),len(type_of_quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "153533a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_9 = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[13]/a\")\n",
    "\n",
    "next_9.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "f7e41a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Quotes from the given page\n",
    "\n",
    "quote_tags = driver.find_elements(By.XPATH, '//a[@class=\"title\"]' )\n",
    "for i in quote_tags[0:100]:\n",
    "    quote_1 = i.text\n",
    "    quote_title.append(quote_1)\n",
    "    \n",
    "    \n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags = driver.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags[0:100]:\n",
    "    author_1 = i.text\n",
    "    authors.append(author_1)\n",
    "    \n",
    "#  Scraping type of quotes from the given page\n",
    "\n",
    "type_tags = driver.find_elements(By.XPATH, '//div[@class=\"tags\"]' )\n",
    "for i in type_tags[0:100]:\n",
    "    type_1 = i.text\n",
    "    type_of_quotes.append(type_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "131feaa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 900 900\n"
     ]
    }
   ],
   "source": [
    "print(len(quote_title),len(authors),len(type_of_quotes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "ca92f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for next button\n",
    "\n",
    "next_10 = driver.find_element(By.XPATH,\"/html/body/div[1]/div[2]/div/div/div/div[1]/div/div[3]/li[13]/a\")\n",
    "\n",
    "next_10.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "c914a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping Quotes from the given page\n",
    "\n",
    "quote_tags = driver.find_elements(By.XPATH, '//a[@class=\"title\"]' )\n",
    "for i in quote_tags[0:100]:\n",
    "    quote_1 = i.text\n",
    "    quote_title.append(quote_1)\n",
    "    \n",
    "    \n",
    "# Scraping author from the given page\n",
    "\n",
    "author_tags = driver.find_elements(By.XPATH, '//div[@class=\"author\"]')\n",
    "for i in author_tags[0:100]:\n",
    "    author_1 = i.text\n",
    "    authors.append(author_1)\n",
    "    \n",
    "#  Scraping type of quotes from the given page\n",
    "\n",
    "type_tags = driver.find_elements(By.XPATH, '//div[@class=\"tags\"]' )\n",
    "for i in type_tags[0:100]:\n",
    "    type_1 = i.text\n",
    "    type_of_quotes.append(type_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "id": "df83fc03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(quote_title),len(authors),len(type_of_quotes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd0eb18a",
   "metadata": {},
   "source": [
    "### Making DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "0849b42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quotes</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Quote_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Quotes             Authors  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                                   Quote_Type  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995         Love, Inspirational, Motivational  \n",
       "996                    Gun, Two, Qualms About  \n",
       "997     Inspirational, Greatness, Best Effort  \n",
       "998                    Spiritual, Truth, Yoga  \n",
       "999      Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Quotes':quote_title, 'Authors':authors, 'Quote_Type':type_of_quotes})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77594438",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777896f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03146e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75ac9052",
   "metadata": {},
   "source": [
    "### Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "226693f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\ASUS\\Downloads\\chromedriver_win32\\Chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13ae0691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the page on automated chrome browser\n",
    "\n",
    "driver.get(' https://www.jagranjosh.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "627d2cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for GK button\n",
    "\n",
    "gk = driver.find_element(By.XPATH,\"/html/body/div/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[9]/a\")\n",
    "\n",
    "gk.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd0ceb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for PM's  button\n",
    "\n",
    "pm = driver.find_element(By.XPATH,\"/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a\")\n",
    "\n",
    "pm.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6ed2be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_title = []\n",
    "dates = []\n",
    "term_of_office = []\n",
    "remarks = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4a2ef8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping All PM's names from the given page\n",
    "\n",
    "pm_tags = driver.find_elements(By.XPATH, '//div[@class=\"table-box\"]/table/tbody/tr/td[2]/p' )\n",
    "for i in pm_tags[0:18]:\n",
    "    pm_1 = i.text\n",
    "    pm_title.append(pm_1)\n",
    "    \n",
    "    \n",
    "# Scraping dates from the given page\n",
    "\n",
    "date_tags = driver.find_elements(By.XPATH, '//div[@class=\"table-box\"]/table/tbody/tr/td[3]/p')\n",
    "for i in date_tags[0:18]:\n",
    "    date_1 = i.text\n",
    "    dates.append(date_1)\n",
    "    \n",
    "# Scraping the term of office from the given page\n",
    "\n",
    "tof_tags = driver.find_elements(By.XPATH, '//div[@class=\"table-box\"]/table/tbody/tr/td[4]/p')\n",
    "for i in tof_tags[0:18]:\n",
    "    tof_1 = i.text\n",
    "    term_of_office.append(tof_1)\n",
    "    \n",
    "    \n",
    "    \n",
    "# Scraping the remarks from the given page\n",
    "\n",
    "remark_tags = driver.find_elements(By.XPATH, '//div[@class=\"table-box\"]/table/tbody/tr/td[5]/p')\n",
    "for i in remark_tags[0:18]:\n",
    "    remark_1 = i.text\n",
    "    remarks.append(remark_1)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5e305dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18 18 18\n"
     ]
    }
   ],
   "source": [
    "print(len(pm_title),len(dates),len(term_of_office),len(remarks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a26c31",
   "metadata": {},
   "source": [
    "### Making DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b75bb13a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name_Of_Prime_Ministers</th>\n",
       "      <th>Born_Dead_date</th>\n",
       "      <th>Term_Of_Office</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>(1889–1964)</td>\n",
       "      <td>15 August 1947 to 27 May 1964</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>16 years, 286 days</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>(1904–1966)</td>\n",
       "      <td>27 May 1964 to 9 June 1964,</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>(1898-1998)</td>\n",
       "      <td>13 days</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>9 June 1964 to 11 January 1966</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>(1896–1995)</td>\n",
       "      <td>1 year, 216 days</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>(1902–1987)</td>\n",
       "      <td>11 January 1966 to 24 January 1966</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>(1917–1984)</td>\n",
       "      <td>13 days</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>(1944–1991)</td>\n",
       "      <td>24 January 1966 to 24 March 1977</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>(1931–2008)</td>\n",
       "      <td>11 years, 59 days</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>(1927–2007)</td>\n",
       "      <td>24 March 1977 to  28 July 1979</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>(1921–2004)</td>\n",
       "      <td>2 year, 126 days</td>\n",
       "      <td>First PM from south India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924- 2018)</td>\n",
       "      <td>28 July 1979 to 14 January 1980</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>(born 1933)</td>\n",
       "      <td>170 days</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>(1919–2012)</td>\n",
       "      <td>14 January 1980 to 31 October 1984</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>(1924-2018)</td>\n",
       "      <td>4 years, 291 days</td>\n",
       "      <td>The first non-congress PM who completed a ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>(born 1932)</td>\n",
       "      <td>31 October 1984 to 2 December 1989</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>(born 1950)</td>\n",
       "      <td>5 years, 32 days</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name_Of_Prime_Ministers Born_Dead_date  \\\n",
       "0             Jawahar Lal Nehru    (1889–1964)   \n",
       "1     Gulzarilal Nanda (Acting)    (1898-1998)   \n",
       "2           Lal Bahadur Shastri    (1904–1966)   \n",
       "3   Gulzari Lal Nanda  (Acting)    (1898-1998)   \n",
       "4                 Indira Gandhi    (1917–1984)   \n",
       "5                 Morarji Desai    (1896–1995)   \n",
       "6                  Charan Singh    (1902–1987)   \n",
       "7                 Indira Gandhi    (1917–1984)   \n",
       "8                  Rajiv Gandhi    (1944–1991)   \n",
       "9                   V. P. Singh    (1931–2008)   \n",
       "10              Chandra Shekhar    (1927–2007)   \n",
       "11          P. V. Narasimha Rao    (1921–2004)   \n",
       "12         Atal Bihari Vajpayee   (1924- 2018)   \n",
       "13             H. D. Deve Gowda    (born 1933)   \n",
       "14           Inder Kumar Gujral    (1919–2012)   \n",
       "15         Atal Bihari Vajpayee    (1924-2018)   \n",
       "16               Manmohan Singh    (born 1932)   \n",
       "17                Narendra Modi    (born 1950)   \n",
       "\n",
       "                        Term_Of_Office  \\\n",
       "0        15 August 1947 to 27 May 1964   \n",
       "1                   16 years, 286 days   \n",
       "2          27 May 1964 to 9 June 1964,   \n",
       "3                              13 days   \n",
       "4       9 June 1964 to 11 January 1966   \n",
       "5                     1 year, 216 days   \n",
       "6   11 January 1966 to 24 January 1966   \n",
       "7                              13 days   \n",
       "8     24 January 1966 to 24 March 1977   \n",
       "9                    11 years, 59 days   \n",
       "10     24 March 1977 to  28 July 1979    \n",
       "11                    2 year, 126 days   \n",
       "12     28 July 1979 to 14 January 1980   \n",
       "13                            170 days   \n",
       "14  14 January 1980 to 31 October 1984   \n",
       "15                   4 years, 291 days   \n",
       "16  31 October 1984 to 2 December 1989   \n",
       "17                    5 years, 32 days   \n",
       "\n",
       "                                              Remarks  \n",
       "0   The first prime minister of India and the long...  \n",
       "1                            First acting PM of India  \n",
       "2   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "3                                                   -  \n",
       "4                First female Prime Minister of India  \n",
       "5   Oldest to become PM (81 years old) and first t...  \n",
       "6             Only PM who did not face the Parliament  \n",
       "7   The first lady who served as PM for the second...  \n",
       "8                Youngest to become PM (40 years old)  \n",
       "9   First PM to step down after a vote of no confi...  \n",
       "10              He belongs to  Samajwadi Janata Party  \n",
       "11                          First PM from south India  \n",
       "12                             PM for shortest tenure  \n",
       "13                          He belongs to  Janata Dal  \n",
       "14                                             ------  \n",
       "15   The first non-congress PM who completed a ful...  \n",
       "16                                      First Sikh PM  \n",
       "17  4th Prime Minister of India who served two con...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Name_Of_Prime_Ministers':pm_title, 'Born_Dead_date':dates, 'Term_Of_Office':term_of_office, 'Remarks':remarks})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1eb12a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6077b923",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9d921c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1ca021af",
   "metadata": {},
   "source": [
    "### Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e.Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.motor1.com/\n",
    "2. Then You have to click on the List option from Dropdown menu on leftside.\n",
    "3. Then click on 50 most expensive carsin the world..\n",
    "4. Then scrap the mentioned data and make the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "71f2799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connect to the driver\n",
    "\n",
    "driver = webdriver.Chrome(r'C:\\Users\\ASUS\\Downloads\\chromedriver_win32\\Chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "id": "0995f498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening the page on automated chrome browser\n",
    "\n",
    "driver.get('https://www.motor1.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "548c71ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for list button\n",
    "\n",
    "list1= driver.find_element(By.XPATH,\"/html/body/div[3]/div[2]/div/div/div[1]/div\")\n",
    "\n",
    "list1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "de234280",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for features button\n",
    "\n",
    "features = driver.find_element(By.XPATH,\"/html/body/div[4]/div[1]/div[3]/ul/li[5]/button\")\n",
    "\n",
    "features.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "083f92af",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for lists button\n",
    "\n",
    "lists = driver.find_element(By.XPATH,\"/html/body/div[4]/div[1]/div[3]/ul/li[6]/ul/li[1]/a\")\n",
    "\n",
    "lists.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "id": "5789b5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for 50 most expensive cars button\n",
    "\n",
    "cars = driver.find_element(By.XPATH,\"/html/body/div[3]/div[8]/div[1]/div[1]/div/div/div[8]/div/div[1]/h3/a\")\n",
    "\n",
    "cars.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "id": "0cd673e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_title = []\n",
    "price = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "bfbbc190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scraping All PM's names from the given page\n",
    "\n",
    "car_tags = driver.find_elements(By.XPATH, '//h3[@class=\"subheader\"]' )\n",
    "for i in car_tags[0:50]:\n",
    "    car_1 = i.text\n",
    "    car_title.append(car_1)\n",
    "    \n",
    "    \n",
    "# Scraping dates from the given page\n",
    "\n",
    "price_tags = driver.find_elements(By.XPATH, \"//strong\")\n",
    "for i in price_tags[0:50]:\n",
    "    price_1 = i.text\n",
    "    price.append(price_1)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "id": "14d2d733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    }
   ],
   "source": [
    "print(len(car_title), len(price))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23cd3c6",
   "metadata": {},
   "source": [
    "### Making DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "id": "6f3b56a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car_Name</th>\n",
       "      <th>Car_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>De Tomaso P72</td>\n",
       "      <td>Price: $1.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ferrari LaFerrari</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pagani Huayra</td>\n",
       "      <td>Price: $1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>McLaren Elva</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>Price: $1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "      <td>Price: $1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "      <td>Price: $1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "      <td>Price: $2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lotus Evija</td>\n",
       "      <td>Price: $2.0 Million*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "      <td>Price: $2.1 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Delage D12</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>Price: $2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "      <td>Price: $2.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ferrari FXX K Evo</td>\n",
       "      <td>Price: $2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "      <td>Price: $2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "      <td>Price: $2.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>Price: $3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "      <td>Price: $3.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>McLaren Solus</td>\n",
       "      <td>Price: $3.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Pagani Huayra Roadster BC</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bugatti Chiron Pur Sport</td>\n",
       "      <td>Price: $3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "      <td>Price: $3.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "      <td>Price: $3.6 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "      <td>Price: $3.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "      <td>Price: $3.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "      <td>Price: $4.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "      <td>Price: $4.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "      <td>Price: $5.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>Price: $5.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "      <td>Price: $5.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "      <td>Price: $6.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "      <td>Price: $7.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "      <td>Price: $8.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bugatti Chiron Profilée</td>\n",
       "      <td>Price: $9.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "      <td>Price: $10.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "      <td>Price: $12.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce Boat Tail*</td>\n",
       "      <td>Price: $13.4 Million</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Car_Name             Car_Price\n",
       "0                     De Tomaso P72   Price: $1.3 Million\n",
       "1                 Ferrari LaFerrari   Price: $1.4 Million\n",
       "2                     Pagani Huayra   Price: $1.4 Million\n",
       "3                      McLaren Elva                      \n",
       "4                       Czinger 21C   Price: $1.7 Million\n",
       "5                     Ferrari Monza   Price: $1.7 Million\n",
       "6                Gordon Murray T.33   Price: $1.7 Million\n",
       "7                 Koenigsegg Gemera   Price: $1.7 Million\n",
       "8                       Zenvo TSR-S   Price: $1.7 Million\n",
       "9                Hennessey Venom F5   Price: $1.7 Million\n",
       "10                  Bentley Bacalar   Price: $1.8 Million\n",
       "11    Hispano Suiza Carmen Boulogne   Price: $1.9 Million\n",
       "12           Bentley Mulliner Batur   Price: $1.9 Million\n",
       "13                     Deus Vayanne   Price: $2.0 Million\n",
       "14                      SSC Tuatara   Price: $2.0 Million\n",
       "15                      Lotus Evija  Price: $2.0 Million*\n",
       "16              Aston Martin Vulcan   Price: $2.1 Million\n",
       "17                       Delage D12   Price: $2.3 Million\n",
       "18                McLaren Speedtail   Price: $2.3 Million\n",
       "19                     Rimac Nevera   Price: $2.3 Million\n",
       "20                    Pagani Utopia   Price: $2.4 Million\n",
       "21             Pininfarina Battista   Price: $2.5 Million\n",
       "22                Ferrari FXX K Evo   Price: $2.5 Million\n",
       "23               Gordon Murray T.50   Price: $2.6 Million\n",
       "24             Lamborghini Countach   Price: $2.6 Million\n",
       "25         Mercedes-AMG Project One   Price: $2.6 Million\n",
       "26              Aston Martin Victor   Price: $2.7 Million\n",
       "27      Hennessey Venom F5 Roadster   Price: $3.0 Million\n",
       "28                 Koenigsegg Jesko          $3.0 Million\n",
       "29            Aston Martin Valkyrie   Price: $3.0 Million\n",
       "30        W Motors Lykan Hypersport   Price: $3.2 Million\n",
       "31                    McLaren Solus   Price: $3.4 Million\n",
       "32        Pagani Huayra Roadster BC          $3.5 Million\n",
       "33         Bugatti Chiron Pur Sport   Price: $3.5 Million\n",
       "34                 Lamborghini Sian   Price: $3.6 Million\n",
       "35                 Koenigsegg CC850   Price: $3.6 million\n",
       "36  Bugatti Chiron Super Sport 300+   Price: $3.7 Million\n",
       "37               Lamborghini Veneno   Price: $3.9 Million\n",
       "38                   Bugatti Bolide   Price: $4.5 Million\n",
       "39                  Bugatti Mistral   Price: $4.7 Million\n",
       "40              Pagani Huayra Imola   Price: $5.0 Million\n",
       "41                     Bugatti Divo   Price: $5.4 Million\n",
       "42              SP Automotive Chaos   Price: $5.8 Million\n",
       "43                 Pagani Codalunga   Price: $6.4 Million\n",
       "44         Mercedes-Maybach Exelero   Price: $7.4 Million\n",
       "45               Bugatti Centodieci   Price: $8.0 Million\n",
       "46          Bugatti Chiron Profilée   Price: $9.0 Million\n",
       "47             Rolls-Royce Sweptail  Price: $10.8 Million\n",
       "48         Bugatti La Voiture Noire  Price: $12.8 Million\n",
       "49           Rolls-Royce Boat Tail*  Price: $13.4 Million"
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Car_Name':car_title, 'Car_Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002c7ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
